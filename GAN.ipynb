{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osgeo\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "    \n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,  Dense, Flatten, Reshape, Dropout, UpSampling2D, Lambda, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster Information:\n",
      "Number of Bands: 4\n",
      "Width: 256\n",
      "Height: 256\n",
      "Coordinate Reference System (CRS): None\n",
      "Transform (Affine): | 1.00, 0.00, 0.00|\n",
      "| 0.00, 1.00, 0.00|\n",
      "| 0.00, 0.00, 1.00|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rasterio\\__init__.py:319: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"images_downscaled\\\\April_7_2022.tif\"\n",
    "dataset = rasterio.open(file_path)\n",
    "\n",
    "# Print general information\n",
    "print(\"Raster Information:\")\n",
    "print(f\"Number of Bands: {dataset.count}\")\n",
    "print(f\"Width: {dataset.width}\")\n",
    "print(f\"Height: {dataset.height}\")\n",
    "print(f\"Coordinate Reference System (CRS): {dataset.crs}\")\n",
    "print(f\"Transform (Affine): {dataset.transform}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downscaling the Images to a (256, 256) Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"images\"\n",
    "output_folder = \"images_downscaled\"\n",
    "target_resolution = (256, 256)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if the file is an image (you can modify the condition based on your image file extensions)\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        # Construct the full paths to the input and output images\n",
    "        input_image_path = os.path.join(input_folder, file_name)\n",
    "        output_image_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Open and resize the input image\n",
    "        input_image = Image.open(input_image_path)\n",
    "        resized_image = input_image.resize(target_resolution)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(output_image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downscaling the Masks to a (256, 256) Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"masks\"\n",
    "output_folder = \"masks_downscaled\"\n",
    "target_resolution = (256, 256)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if the file is an image (you can modify the condition based on your image file extensions)\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        # Construct the full paths to the input and output images\n",
    "        input_image_path = os.path.join(input_folder, file_name)\n",
    "        output_image_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Open and resize the input image\n",
    "        input_image = Image.open(input_image_path)\n",
    "        resized_image = input_image.resize(target_resolution)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'batch_normalization' (type BatchNormalization).\n\nunhashable type: 'list'\n\nCall arguments received by layer 'batch_normalization' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(None, 128, 128, 128), dtype=float32)\n  • training=[\"<KerasTensor: shape=(None, 256, 256, 1) dtype=float32 (created by layer 'sequential_4')>\", \"<KerasTensor: shape=(None, 256, 256, 1) dtype=float32 (created by layer 'sequential_5')>\"]\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 125\u001b[0m\n\u001b[0;32m    118\u001b[0m     mask \u001b[39m=\u001b[39m mask_model(noise)\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m model(noise, [img, mask])\n\u001b[1;32m--> 125\u001b[0m generator \u001b[39m=\u001b[39m build_generator()\n\u001b[0;32m    127\u001b[0m generator\u001b[39m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[36], line 120\u001b[0m, in \u001b[0;36mbuild_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m mask_model\u001b[39m.\u001b[39madd(Activation(\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    118\u001b[0m mask \u001b[39m=\u001b[39m mask_model(noise)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m model(noise, [img, mask])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\control_flow_util.py:129\u001b[0m, in \u001b[0;36mconstant_value\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mget_static_value(pred)\n\u001b[1;32m--> 129\u001b[0m \u001b[39mif\u001b[39;00m pred \u001b[39min\u001b[39;49;00m {\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m}:  \u001b[39m# Accept 1/0 as valid boolean values\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(pred)\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, \u001b[39mbool\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'batch_normalization' (type BatchNormalization).\n\nunhashable type: 'list'\n\nCall arguments received by layer 'batch_normalization' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(None, 128, 128, 128), dtype=float32)\n  • training=[\"<KerasTensor: shape=(None, 256, 256, 1) dtype=float32 (created by layer 'sequential_4')>\", \"<KerasTensor: shape=(None, 256, 256, 1) dtype=float32 (created by layer 'sequential_5')>\"]\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# def build_generator():\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Dense(256*256, input_dim = 100))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Reshape((256, 256, 1))) # 1 is the number of channels\n",
    "\n",
    "#     # Upsampling Block 1\n",
    "#     model.add(UpSampling2D())\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Upsampling Block 2\n",
    "#     model.add(UpSampling2D())\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Convolutional Block 1\n",
    "#     model.add(Conv2D(64, 2, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Convolutuonal Block 2\n",
    "#     model.add(Conv2D(64, 2, padding ='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Convolutional layer to get to one channel\n",
    "#     model.add(Conv2D(1, 1, padding='same', activation='sigmoid'))\n",
    "\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def build_generator():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Dense(64 * 64 * 1, input_dim=100))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Reshape((64, 64, 1)))\n",
    "\n",
    "#     # Upsampling Block 1\n",
    "#     model.add(UpSampling2D())\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Upsampling Block 2\n",
    "#     model.add(UpSampling2D())\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Convolutional Block 1\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # Convolutional Block 2\n",
    "#     model.add(Conv2D(64, 3, padding='same'))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "\n",
    "#     # # Convolutional layer to get to one channel\n",
    "#     # model.add(Conv2D(1, 3, padding='same', activation='sigmoid'))\n",
    "\n",
    "#     # Last layer of the generator\n",
    "#     model.add(Conv2D(1, 3, padding='same', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 64 * 64, activation='relu', input_dim=100))\n",
    "    model.add(Reshape((64, 64, 128)))\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(1, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    noise = Input(shape=(100,))\n",
    "    img = model(noise)\n",
    "\n",
    "    # This is where you create the mask generator\n",
    "    mask_model = Sequential()\n",
    "\n",
    "    mask_model.add(Dense(128 * 64 * 64, activation='relu', input_dim=100))\n",
    "    mask_model.add(Reshape((64, 64, 128)))\n",
    "    mask_model.add(UpSampling2D())\n",
    "    \n",
    "    mask_model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "    mask_model.add(BatchNormalization(momentum=0.8))\n",
    "    mask_model.add(Activation('relu'))\n",
    "    mask_model.add(UpSampling2D())\n",
    "    \n",
    "    mask_model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "    mask_model.add(BatchNormalization(momentum=0.8))\n",
    "    mask_model.add(Activation('relu'))\n",
    "    \n",
    "    mask_model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "    mask_model.add(BatchNormalization(momentum=0.8))\n",
    "    mask_model.add(Activation('relu'))\n",
    "    \n",
    "    mask_model.add(Conv2D(1, kernel_size=3, padding='same'))\n",
    "    mask_model.add(Activation('sigmoid'))\n",
    "\n",
    "    mask = mask_model(noise)\n",
    "\n",
    "    return model(noise, [img, mask])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "generator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_discriminator():\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # Convolutional Block 1\n",
    "#     model.add(Conv2D(64, (3, 3), strides=(2, 2), input_shape=(256, 256, 1)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 2\n",
    "#     model.add(Conv2D(128, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 3\n",
    "#     model.add(Conv2D(256, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 4\n",
    "#     model.add(Conv2D(512, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Flatten and then Condense into 1\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def build_discriminator():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # Convolutional Block 1\n",
    "#     model.add(Conv2D(64, (3, 3), strides=(2, 2), input_shape=(256, 256, 1)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 2\n",
    "#     model.add(Conv2D(128, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 3\n",
    "#     model.add(Conv2D(256, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Convolutional Block 4\n",
    "#     model.add(Conv2D(512, (3, 3)))\n",
    "#     model.add(LeakyReLU(0.2))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     # Flatten and then Condense into 1\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_discriminator():\n",
    "    # Input: Image\n",
    "    img_input = Input(shape=(256, 256, 1))\n",
    "    \n",
    "    # Input: Mask\n",
    "    mask_input = Input(shape=(256, 256, 1))\n",
    "    \n",
    "    # Concatenate image and mask along the channel dimension\n",
    "    merged = Concatenate(axis=-1)([img_input, mask_input])\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2))(merged)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    x = Conv2D(256, (3, 3))(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    x = Conv2D(512, (3, 3))(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Flatten and then Condense into 1\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    validity = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model([img_input, mask_input], validity)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 2)  0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 127, 127, 64  1216        ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 127, 127, 64  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 127, 127, 64  0           ['leaky_re_lu_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 125, 125, 12  73856       ['dropout_5[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 125, 125, 12  0           ['conv2d_10[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 125, 125, 12  0           ['leaky_re_lu_10[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 123, 123, 25  295168      ['dropout_6[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 123, 123, 25  0           ['conv2d_11[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 123, 123, 25  0           ['leaky_re_lu_11[0][0]']         \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 121, 121, 51  1180160     ['dropout_7[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 121, 121, 51  0           ['conv2d_12[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 121, 121, 51  0           ['leaky_re_lu_12[0][0]']         \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 7496192)      0           ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 7496192)      0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            7496193     ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,046,593\n",
      "Trainable params: 9,046,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Compile the discriminator\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def convert_to_grayscale(input_dir, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Get list of all file paths in the directory\n",
    "    image_files = os.listdir(input_dir)\n",
    "\n",
    "    # Iterate over each file\n",
    "    for file in image_files:\n",
    "        # Ensure the file is a .tif\n",
    "        if file.endswith('.tif') or file.endswith('.tiff'):\n",
    "            # Create full input file path\n",
    "            input_file_path = os.path.join(input_dir, file)\n",
    "            # Create full output file path\n",
    "            output_file_path = os.path.join(output_dir, file)\n",
    "            \n",
    "            # Open the image file\n",
    "            with Image.open(input_file_path) as img:\n",
    "                # Convert the image to grayscale\n",
    "                grayscale_img = img.convert(\"L\")\n",
    "                # Save the grayscale image to the output file\n",
    "                grayscale_img.save(output_file_path)\n",
    "\n",
    "# Call the function with your specific directories\n",
    "convert_to_grayscale(input_dir='masks_downscaled', output_dir='masks_grayscale')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m mask \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):  \u001b[39m# take one sample from the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(mask)  \u001b[39m# this should print the tensor representation of the mask\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3043\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3041\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3042\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 3043\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3044\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   3045\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for mask in dataset.take(1):  # take one sample from the dataset\n",
    "    print(mask)  # this should print the tensor representation of the mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of image and mask files\n",
    "image_folder = \"images_downscaled\"\n",
    "mask_folder = \"masks_grayscale\"\n",
    "image_files = os.listdir(image_folder)\n",
    "mask_files = os.listdir(mask_folder)\n",
    "\n",
    "# Set the number of training iterations\n",
    "epochs = 100\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(epoch):\n",
    "    # Generate fake images\n",
    "    noise = np.random.normal(0, 1, (10, 100))\n",
    "    fake_images = generator.predict(noise)\n",
    "\n",
    "    # Create a directory to save the generated images\n",
    "    save_dir = \"generated_images\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Save the generated images\n",
    "    for i, image in enumerate(fake_images):\n",
    "        filename = f\"generated_image_{epoch}_{i}.png\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        Image.fromarray(image).save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 273ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Generate fake images and masks\u001b[39;00m\n\u001b[0;32m     19\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, (batch_size, \u001b[39m100\u001b[39m))\n\u001b[1;32m---> 20\u001b[0m fake_images, fake_masks \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mpredict(noise)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Train the discriminator\u001b[39;00m\n\u001b[0;32m     23\u001b[0m real_validity \u001b[39m=\u001b[39m discriminator\u001b[39m.\u001b[39mtrain_on_batch([real_images, real_masks], np\u001b[39m.\u001b[39mones((batch_size, \u001b[39m1\u001b[39m)))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # ---------------------\n",
    "    # Train the discriminator\n",
    "    # ---------------------\n",
    "    # Select a random batch of images and masks\n",
    "    idx = np.random.randint(0, len(image_files), batch_size)\n",
    "    real_images = []\n",
    "    real_masks = []\n",
    "    for i in idx:\n",
    "        image = np.array(Image.open(os.path.join(image_folder, image_files[i])))\n",
    "        mask = np.array(Image.open(os.path.join(mask_folder, mask_files[i])))\n",
    "        real_images.append(image)\n",
    "        real_masks.append(mask)\n",
    "    real_images = np.array(real_images) / 255.\n",
    "    real_masks = np.array(real_masks) / 255.\n",
    "\n",
    "    # Generate fake images and masks\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    fake_images, fake_masks = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_validity = discriminator.train_on_batch([real_images, real_masks], np.ones((batch_size, 1)))\n",
    "    fake_validity = discriminator.train_on_batch([fake_images, fake_masks], np.zeros((batch_size, 1)))\n",
    "    discriminator_loss = 0.5 * np.add(real_validity, fake_validity)\n",
    "\n",
    "    # ---------------------\n",
    "    # Train the generator\n",
    "    # ---------------------\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    # The generator wants the discriminator to label the generated samples\n",
    "    # as real (ones)\n",
    "    validity_y = np.array([1] * batch_size)\n",
    "\n",
    "    # Train the generator\n",
    "    generator_loss = combined_model.train_on_batch(noise, validity_y)\n",
    "\n",
    "    # Print the progress\n",
    "    print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, discriminator_loss, generator_loss))\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % save_interval == 0:\n",
    "        save_imgs(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
