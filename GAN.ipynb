{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osgeo\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "    \n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,  Dense, Flatten, Reshape, Dropout, UpSampling2D, Lambda\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster Information:\n",
      "Number of Bands: 4\n",
      "Width: 256\n",
      "Height: 256\n",
      "Coordinate Reference System (CRS): None\n",
      "Transform (Affine): | 1.00, 0.00, 0.00|\n",
      "| 0.00, 1.00, 0.00|\n",
      "| 0.00, 0.00, 1.00|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rasterio\\__init__.py:319: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"images_downscaled\\\\April_7_2022.tif\"\n",
    "dataset = rasterio.open(file_path)\n",
    "\n",
    "# Print general information\n",
    "print(\"Raster Information:\")\n",
    "print(f\"Number of Bands: {dataset.count}\")\n",
    "print(f\"Width: {dataset.width}\")\n",
    "print(f\"Height: {dataset.height}\")\n",
    "print(f\"Coordinate Reference System (CRS): {dataset.crs}\")\n",
    "print(f\"Transform (Affine): {dataset.transform}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downscaling the Images to a (256, 256) Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"images\"\n",
    "output_folder = \"images_downscaled\"\n",
    "target_resolution = (256, 256)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if the file is an image (you can modify the condition based on your image file extensions)\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        # Construct the full paths to the input and output images\n",
    "        input_image_path = os.path.join(input_folder, file_name)\n",
    "        output_image_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Open and resize the input image\n",
    "        input_image = Image.open(input_image_path)\n",
    "        resized_image = input_image.resize(target_resolution)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(output_image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downscaling the Masks to a (256, 256) Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"masks\"\n",
    "output_folder = \"masks_downscaled\"\n",
    "target_resolution = (256, 256)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over the files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    # Check if the file is an image (you can modify the condition based on your image file extensions)\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        # Construct the full paths to the input and output images\n",
    "        input_image_path = os.path.join(input_folder, file_name)\n",
    "        output_image_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Open and resize the input image\n",
    "        input_image = Image.open(input_image_path)\n",
    "        resized_image = input_image.resize(target_resolution)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 65536)             6619136   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 65536)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 512, 512, 1)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 512, 512, 64)      640       \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512, 512, 64)      0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 1024, 1024, 64)   0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1024, 1024, 64)    36928     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 1024, 1024, 64)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1024, 1024, 64)    16448     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 1024, 1024, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1024, 1024, 64)    16448     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 1024, 1024, 64)    0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1024, 1024, 1)     65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,689,665\n",
      "Trainable params: 6,689,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256*256, input_dim = 100))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((256, 256, 1))) # 1 is the number of channels\n",
    "\n",
    "    # Upsampling Block 1\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, 3, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Upsampling Block 2\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, 3, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    model.add(Conv2D(64, 2, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Convolutuonal Block 2\n",
    "    model.add(Conv2D(64, 2, padding ='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # Convolutional layer to get to one channel\n",
    "    model.add(Conv2D(1, 1, padding='same', activation='tanh'))\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "generator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 128, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn(\u001b[39m4\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m1\u001b[39;49m)) \u001b[39m# generates 4 random images\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqtirmvk4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\remne\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "img = generator.predict(np.random.randn(4, 128, 1)) # generates 4 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
